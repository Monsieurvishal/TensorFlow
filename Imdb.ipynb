{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imdb.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uOKZYNceDLe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49600dad-fc0e-4d2e-85f4-9633906a4f78"
      },
      "source": [
        "import keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmJH8UNQPhAt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "33a83397-fb06-4ad3-f99c-4d44bca36246"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKforUznPvGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9351d96b-94c2-4400-8480-b38f5f161623"
      },
      "source": [
        "max([max(sequence) for sequence in train_data])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPd4lcHTQyjd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6ec5a159-b3de-44c1-ae1e-718171351875"
      },
      "source": [
        "# word_index is a dictionary mapping words to an integer index\n",
        "word_index = imdb.get_word_index()\n",
        "# We reverse it, mapping integer indices to words\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "# We decode the review; note that our indices were offset by 3\n",
        "# because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\n",
        "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQM0HwKgRX25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXELEfCmVLbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our vectorized labels\n",
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAeGEFqnXlCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our vectorized training data\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# Our vectorized test data\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jeQydL1VxpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRNckVzzW5r_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Vh1af0W-S4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bvs8QYOXHH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import losses\n",
        "from keras import metrics\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss=losses.binary_crossentropy,\n",
        "              metrics=[metrics.binary_accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqoTp0nRXPsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dANw8tGHXXq6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "91673ca2-94c4-43a3-e78a-173e223774f7"
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 2s 123us/step - loss: 0.4959 - binary_accuracy: 0.7983 - val_loss: 0.4436 - val_binary_accuracy: 0.7976\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 100us/step - loss: 0.2932 - binary_accuracy: 0.9039 - val_loss: 0.3039 - val_binary_accuracy: 0.8827\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 1s 99us/step - loss: 0.2146 - binary_accuracy: 0.9283 - val_loss: 0.2935 - val_binary_accuracy: 0.8835\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 100us/step - loss: 0.1671 - binary_accuracy: 0.9444 - val_loss: 0.2724 - val_binary_accuracy: 0.8918\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 99us/step - loss: 0.1387 - binary_accuracy: 0.9551 - val_loss: 0.3238 - val_binary_accuracy: 0.8731\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 0.1167 - binary_accuracy: 0.9635 - val_loss: 0.2955 - val_binary_accuracy: 0.8845\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 102us/step - loss: 0.0947 - binary_accuracy: 0.9713 - val_loss: 0.3266 - val_binary_accuracy: 0.8799\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 100us/step - loss: 0.0808 - binary_accuracy: 0.9756 - val_loss: 0.3397 - val_binary_accuracy: 0.8847\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.0650 - binary_accuracy: 0.9831 - val_loss: 0.3579 - val_binary_accuracy: 0.8824\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 103us/step - loss: 0.0562 - binary_accuracy: 0.9850 - val_loss: 0.3814 - val_binary_accuracy: 0.8791\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 101us/step - loss: 0.0431 - binary_accuracy: 0.9897 - val_loss: 0.4290 - val_binary_accuracy: 0.8712\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 100us/step - loss: 0.0347 - binary_accuracy: 0.9923 - val_loss: 0.4507 - val_binary_accuracy: 0.8711\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 2s 101us/step - loss: 0.0291 - binary_accuracy: 0.9941 - val_loss: 0.4745 - val_binary_accuracy: 0.8715\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 99us/step - loss: 0.0233 - binary_accuracy: 0.9960 - val_loss: 0.5224 - val_binary_accuracy: 0.8707\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.0194 - binary_accuracy: 0.9965 - val_loss: 0.5648 - val_binary_accuracy: 0.8640\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 100us/step - loss: 0.0163 - binary_accuracy: 0.9972 - val_loss: 0.5745 - val_binary_accuracy: 0.8691\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 100us/step - loss: 0.0090 - binary_accuracy: 0.9995 - val_loss: 0.6259 - val_binary_accuracy: 0.8637\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 0.0127 - binary_accuracy: 0.9980 - val_loss: 0.6595 - val_binary_accuracy: 0.8655\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 101us/step - loss: 0.0051 - binary_accuracy: 0.9998 - val_loss: 0.6981 - val_binary_accuracy: 0.8629\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 98us/step - loss: 0.0063 - binary_accuracy: 0.9989 - val_loss: 0.7294 - val_binary_accuracy: 0.8670\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}